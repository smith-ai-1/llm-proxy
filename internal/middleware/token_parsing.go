package middleware

import (
	"bytes"
	"compress/gzip"
	"fmt"
	"io"
	"log"
	"net/http"
	"strings"

	"github.com/Instawork/llm-proxy/internal/providers"
)

// MetadataCallback is a function that can be hooked into the TokenParsingMiddleware
// to process LLM response metadata.
type MetadataCallback func(r *http.Request, metadata *providers.LLMResponseMetadata)

// GetProviderFromRequest determines which provider to use based on the request path
func GetProviderFromRequest(providerManager *providers.ProviderManager, req *http.Request) providers.Provider {
	path := req.URL.Path

	// Handle /meta/:userID/provider/ pattern first
	if strings.HasPrefix(path, "/meta/") {
		parts := strings.Split(path, "/")
		if len(parts) >= 4 { // ["", "meta", "userID", "provider", ...]
			providerName := parts[3]
			switch providerName {
			case "openai":
				return providerManager.GetProvider("openai")
			case "anthropic":
				return providerManager.GetProvider("anthropic")
			case "gemini":
				return providerManager.GetProvider("gemini")
			case "groq":
				return providerManager.GetProvider("groq")
			}
		}
	}

	// Handle direct provider paths (legacy support)
	if strings.HasPrefix(path, "/openai/") {
		return providerManager.GetProvider("openai")
	} else if strings.HasPrefix(path, "/anthropic/") {
		return providerManager.GetProvider("anthropic")
	} else if strings.HasPrefix(path, "/gemini/") {
		return providerManager.GetProvider("gemini")
	} else if strings.HasPrefix(path, "/groq/") {
		return providerManager.GetProvider("groq")
	}

	return nil
}

// TokenParsingMiddleware intercepts responses to parse and log token usage
func TokenParsingMiddleware(providerManager *providers.ProviderManager, callbacks ...MetadataCallback) func(http.Handler) http.Handler {
	return func(next http.Handler) http.Handler {
		return http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) {
			// Determine which provider this request is for
			provider := GetProviderFromRequest(providerManager, r)

			// Check if this is a streaming request
			isStreaming := providerManager.IsStreamingRequest(r)

			// Create a custom response writer that can capture the response
			captureWriter := &responseCapture{
				ResponseWriter: w,
				body:           &bytes.Buffer{},
				isStreaming:    isStreaming,
				provider:       provider,
				lastMetadata:   nil,
			}

			// Debug logging
			log.Printf("ğŸ” Debug: Request path: %s, Provider: %v", r.URL.Path, provider != nil)

			next.ServeHTTP(captureWriter, r)

			// Debug logging for endpoint matching
			isAPIEndpoint := strings.Contains(r.URL.Path, "/chat/completions") ||
				strings.Contains(r.URL.Path, "/completions") ||
				strings.Contains(r.URL.Path, "/messages") ||
				strings.Contains(r.URL.Path, ":generateContent") ||
				strings.Contains(r.URL.Path, ":streamGenerateContent")

			log.Printf("ğŸ” Debug: Provider: %v, API endpoint: %v, Response body length: %d",
				provider != nil, isAPIEndpoint, captureWriter.body.Len())

			// Only process if we have a provider and this is an API endpoint
			if provider != nil && isAPIEndpoint {
				var metadata *providers.LLMResponseMetadata
				var err error

				// For streaming responses, use the last metadata captured during streaming
				if isStreaming && captureWriter.lastMetadata != nil {
					metadata = captureWriter.lastMetadata
					log.Printf("ğŸ” Token Parser: Using captured streaming metadata - Input: %d, Output: %d, Total: %d",
						metadata.InputTokens, metadata.OutputTokens, metadata.TotalTokens)
				} else {
					// For non-streaming responses, parse the final response
					bodyReader := bytes.NewReader(captureWriter.body.Bytes())
					metadata, err = provider.ParseResponseMetadata(bodyReader, isStreaming)
					if isStreaming && metadata != nil {
						log.Printf("ğŸ” Token Parser: Got final parse metadata - Input: %d, Output: %d, Total: %d",
							metadata.InputTokens, metadata.OutputTokens, metadata.TotalTokens)
					}
				}

				if err != nil {
					// For streaming responses, partial data is expected and not necessarily an error
					if isStreaming {
						log.Printf("Info: Partial streaming response data for %s: %v", provider.GetName(), err)
					} else {
						log.Printf("Warning: Failed to parse response metadata for %s: %v", provider.GetName(), err)
					}
					// Add debug logging for response body if parsing fails
					if captureWriter.body.Len() > 0 {
						bodyBytes := captureWriter.body.Bytes()
						previewBytes := bodyBytes[:min(200, len(bodyBytes))]

						// Check for gzip magic number (0x1f, 0x8b)
						if len(previewBytes) >= 2 && previewBytes[0] == 0x1f && previewBytes[1] == 0x8b {
							// Try to decompress for preview
							if decompressed, err := decompressForPreview(bodyBytes); err == nil {
								previewLen := min(200, len(decompressed))
								log.Printf("ğŸ” Debug: Response body is gzip compressed, decompressed preview: %s", string(decompressed[:previewLen]))
							} else {
								log.Printf("ğŸ” Debug: Response body is gzip compressed (failed to decompress for preview): %v", err)
							}
						} else {
							log.Printf("ğŸ” Debug: Response body preview: %s", string(previewBytes))
						}
					}
				} else if metadata != nil {
					// Log the metadata for cost tracking
					log.Printf("ğŸ”¢ LLM Response Metadata:\n"+
						"   Provider: %s\n"+
						"   Model: %s\n"+
						"   Request ID: %s\n"+
						"   Input Tokens: %d\n"+
						"   Output Tokens: %d\n"+
						"   Total Tokens: %d\n"+
						"   Streaming: %t\n"+
						"   Finish Reason: %s",
						metadata.Provider, metadata.Model, metadata.RequestID, metadata.InputTokens, metadata.OutputTokens,
						metadata.TotalTokens, metadata.IsStreaming, metadata.FinishReason)

					// Additional detailed logging for cost tracking
					if metadata.TotalTokens > 0 {
						// Include thought tokens in the logging if available
						log.Printf("ğŸ’° Token Usage Summary:\n"+
							"   Provider/Model: %s/%s\n"+
							"   Input Tokens: %d\n"+
							"   Output Tokens: %d\n"+
							"   Thought Tokens: %d\n"+
							"   Total Tokens: %d",
							metadata.Provider, metadata.Model, metadata.InputTokens, metadata.OutputTokens, metadata.ThoughtTokens, metadata.TotalTokens)
					} else if metadata.IsStreaming {
						log.Printf("â„¹ï¸  Streaming Response: Usage information not yet available (partial response captured)")
					}

					// Add custom header with token usage information
					w.Header().Set("X-LLM-Input-Tokens", fmt.Sprintf("%d", metadata.InputTokens))
					w.Header().Set("X-LLM-Output-Tokens", fmt.Sprintf("%d", metadata.OutputTokens))
					w.Header().Set("X-LLM-Total-Tokens", fmt.Sprintf("%d", metadata.TotalTokens))
					w.Header().Set("X-LLM-Thought-Tokens", fmt.Sprintf("%d", metadata.ThoughtTokens))
					w.Header().Set("X-LLM-Provider", metadata.Provider)
					w.Header().Set("X-LLM-Model", metadata.Model)
					if metadata.RequestID != "" {
						w.Header().Set("X-LLM-Request-ID", metadata.RequestID)
					}

					// Execute all registered callbacks with the metadata
					for _, callback := range callbacks {
						if callback != nil {
							callback(r, metadata)
						}
					}
				} else if isStreaming {
					// For streaming responses without metadata, just log that we're still waiting
					log.Printf("â„¹ï¸  Streaming Response: Still waiting for complete usage information")
				}
			}
		})
	}
}

// responseCapture captures the response body for parsing
type responseCapture struct {
	http.ResponseWriter
	body          *bytes.Buffer
	isStreaming   bool
	provider      providers.Provider
	lastMetadata  *providers.LLMResponseMetadata
	lastParsedPos int // Track the last position we parsed to avoid re-parsing
}

func (rc *responseCapture) Write(b []byte) (int, error) {
	// Write to both the original response and our buffer
	rc.body.Write(b)

	// For streaming responses, only parse new data to avoid redundant parsing
	if rc.isStreaming && rc.provider != nil {
		// Get the current buffer content
		allData := rc.body.Bytes()

		// Only parse if we have new data since the last parse
		if len(allData) > rc.lastParsedPos {
			log.Printf("ğŸ” Token Parser: Parsing streaming data, buffer size: %d, new data: %d bytes",
				len(allData), len(allData)-rc.lastParsedPos)

			// For streaming, we need to parse the entire buffer since usage info
			// comes at the end and we might have partial events
			bodyReader := bytes.NewReader(allData)
			if metadata, err := rc.provider.ParseResponseMetadata(bodyReader, true); err == nil && metadata != nil {
				log.Printf("ğŸ” Token Parser: Got metadata - Input: %d, Output: %d, Total: %d",
					metadata.InputTokens, metadata.OutputTokens, metadata.TotalTokens)
				// Update the last successful metadata
				rc.lastMetadata = metadata
			} else if err != nil {
				log.Printf("ğŸ” Token Parser: Parse error (expected for partial data): %v", err)
			}
			// Update the last parsed position
			rc.lastParsedPos = len(allData)
		}
	}

	return rc.ResponseWriter.Write(b)
}

// Helper function to find minimum of two integers
func min(a, b int) int {
	if a < b {
		return a
	}
	return b
}

// ExtractUserIDFromRequest extracts user ID from request headers, query parameters, or provider-specific methods
// Follows the priority order: context (from meta URL) â†’ URL path â†’ headers â†’ query parameters â†’ provider-specific extraction â†’ fallback to IP
func ExtractUserIDFromRequest(req *http.Request, provider providers.Provider) string {
	// Priority 0: Check for user ID in request context (from meta URL rewriting)
	if userID, ok := req.Context().Value(userIDContextKey).(string); ok && userID != "" {
		log.Printf("ğŸ” User ID from context: %s", userID)
		return userID
	}

	// Priority 1: Check for user ID in URL path for meta prefix pattern
	path := req.URL.Path
	if strings.HasPrefix(path, "/meta/") {
		parts := strings.Split(path, "/")
		if len(parts) >= 3 { // ["", "meta", "userID", ...]
			userID := parts[2]
			if userID != "" {
				log.Printf("ğŸ” User ID from URL path: %s", userID)
				return userID
			}
		}
	}

	// Priority 2: Check for custom user ID header
	if userID := req.Header.Get("X-User-ID"); userID != "" {
		log.Printf("ğŸ” User ID from X-User-ID header: %s", userID)
		return userID
	}

	// Priority 3: Provider-specific extraction from request body
	if provider != nil {
		if userID := provider.UserIDFromRequest(req); userID != "" {
			log.Printf("ğŸ” User ID from provider-specific extraction: %s", userID)
			return userID
		}
	}

	// Priority 4: Check query parameters
	if userID := req.URL.Query().Get("llm_user_id"); userID != "" {
		log.Printf("ğŸ” User ID from query parameter: %s", userID)
		return userID
	}

	// Priority 5: Check Authorization header for API key or JWT token
	if auth := req.Header.Get("Authorization"); auth != "" {
		// For API keys, use a hash of the key as user ID (for privacy)
		if strings.HasPrefix(auth, "Bearer ") {
			// Use first 8 characters of the token for identification
			token := auth[7:]
			if len(token) > 8 {
				tokenID := fmt.Sprintf("token:%s", token[:8])
				log.Printf("ğŸ” User ID from Authorization header: %s", tokenID)
				return tokenID
			}
			tokenID := fmt.Sprintf("token:%s", token)
			log.Printf("ğŸ” User ID from Authorization header: %s", tokenID)
			return tokenID
		}
	}

	// Fallback to IP address if no user identification
	ipAddr := ExtractIPAddressFromRequest(req)
	log.Printf("ğŸ” User ID fallback to IP address: %s", ipAddr)
	return fmt.Sprintf("ip:%s", ipAddr)
}

// ExtractIPAddressFromRequest extracts IP address from request headers
func ExtractIPAddressFromRequest(req *http.Request) string {
	// Check for forwarded headers
	if forwarded := req.Header.Get("X-Forwarded-For"); forwarded != "" {
		return forwarded
	}

	if realIP := req.Header.Get("X-Real-IP"); realIP != "" {
		return realIP
	}

	return req.RemoteAddr
}

// decompressForPreview safely decompresses gzip data for debug preview purposes
func decompressForPreview(data []byte) ([]byte, error) {
	// Check for gzip magic number
	if len(data) < 2 || data[0] != 0x1f || data[1] != 0x8b {
		return nil, fmt.Errorf("not gzip compressed")
	}

	// Create a gzip reader
	reader := bytes.NewReader(data)
	gzipReader, err := gzip.NewReader(reader)
	if err != nil {
		return nil, fmt.Errorf("failed to create gzip reader: %w", err)
	}
	defer gzipReader.Close()

	// Read the decompressed data
	decompressed, err := io.ReadAll(gzipReader)
	if err != nil {
		return nil, fmt.Errorf("failed to decompress data: %w", err)
	}

	return decompressed, nil
}
